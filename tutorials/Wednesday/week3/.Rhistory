y <- c(105, 69, 86, 100, 82, 111, 104, 110, 87, 108, 87, 90, 94, 113, 112, 98, 80, 97, 95, 111, 114, 89, 95, 126, 98)
CI <-c(mean(y) - qnorm((1-0.9)/2 ,lower.tail = FALSE)*sd(y)/sqrt(25) , mean(y) + qnorm((1-0.9)/2 ,lower.tail = FALSE)*sd(y)/sqrt(25) )
c
CI
?qnorm
qnorm((1-0.9)/2 ,lower.tail = FALSE)
qnorm((1-0.9)/2 ,lower.tail = TRUE)
sample_mean <- mean(y)
sample_mean
CI <-c(mean(y) - qt((1-0.9)/2 ,lower.tail = FALSE)*sd(y)/sqrt(25) , mean(y) + qt((1-0.9)/2 ,lower.tail = FALSE)*sd(y)/sqrt(25) )
CI <-c(mean(y) - qt((1-0.9)/2 ,lower.tail = FALSE,df = length(y) -1 )*sd(y)/sqrt(25) , mean(y) + qt((1-0.9)/2 ,lower.tail = FALSE,df = length(y) -1 )*sd(y)/sqrt(25) )
CI
?t.test
t.test(y, mu=100 )
expenditure <- read.table("https://raw.githubusercontent.com/ASDS-TCD/StatsI_Fall2024/main/datasets/expenditure.txt", header=T)
expenditure
plot(expenditure$Y,expenditure$X1)
pairs(expenditure)
pairs(expenditure[2:5])
# remove objects
rm(list=ls())
# detach all libraries
detachAllPackages <- function() {
basic.packages <- c("package:stats", "package:graphics", "package:grDevices", "package:utils", "package:datasets", "package:methods", "package:base")
package.list <- search()[ifelse(unlist(gregexpr("package:", search()))==1, TRUE, FALSE)]
package.list <- setdiff(package.list, basic.packages)
if (length(package.list)>0)  for (package in package.list) detach(package,  character.only = TRUE)
}
detachAllPackages()
# load libraries
pkgTest <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[,  "Package"])]
if (length(new.pkg))
install.packages(new.pkg,  dependencies = TRUE)
sapply(pkg,  require,  character.only = TRUE)
}
# here is where you load any necessary packages
# ex: stringr
# lapply(c("stringr"),  pkgTest)
lapply(c("tidyverse", "stargazer"),  pkgTest)
# set working directory
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
getwd()
# Agenda
# (a.) Contingency tables
# (b.) Chi-square test
# (c.) Correlation
# (d.) Bivariate regression
# Load data
dm_not_tidy <- read.csv("movies.csv")
# First step, look at data
View(dm_not_tidy)
str(dm_not_tidy)
head(dm_not_tidy)
summary(dm_not_tidy)
# Load tidy version of data
# The data is prepared using the data_wraning.R script.
dm <- readRDS("movies_updated.rds")
str(dm)
table(dm$genre, # Genre
dm$critics_rating) # Rating
dm_s <- dm[dm$genre=="Comedy" |
dm$genre=="Drama" |
dm$genre=="Documentary", ]
View(dm_s)
# Step by step
dm$genre # Select column
# For each row, value=="Comedy" or "Drama" or "Documentary"?
dm$genre=="Comedy" | dm$genre=="Drama" | dm$genre=="Documentary"
# Select rows with value=="Comedy" or "Drama" or "Documentary"
dm[dm$genre=="Comedy" |
dm$genre=="Drama" |
dm$genre=="Documentary", ]
dm_s <- dm[dm$genre=="Comedy" |
dm$genre=="Drama" |
dm$genre=="Documentary", ]
View(dm_s)
dm_s <- subset(dm, dm$genre %in% c("Comedy","Documentary","Drama"))
View(dm_s)
?subset
# Contingency table
table(dm_s$genre, # Genre
dm_s$critics_rating) # Rating
# Problem: Although we filtered our data
# the underlying levels still exist. Getting rid of
# these, we use the droplevels-function.
class(dm_s$genre)
levels(dm_s$genre)
dm_s$genre <- droplevels(dm_s$genre)
class(dm_s$genre)
levels(dm_s$genre)
table(dm_s$genre, # Genre
dm_s$critics_rating) # Rating
addmargins(table(dm_s$genre, # Genre
dm_s$critics_rating)) # Rating
prop.table(table(dm_s$genre,
dm_s$critics_rating))
# What is the probability of a Comedy and "Rotten"?
63/444
# (A) Conditional probability
# What is the probability of "Rotten",
# conditional on Comedy?
?prop.table()
prop.table(table(dm_s$genre, # rows
dm_s$critics_rating), # columns
margin = 1) # over rows
addmargins(prop.table(table(dm_s$genre,
dm_s$critics_rating),
margin = 1)) # over rows
round(addmargins(prop.table(table(dm_s$genre,
dm_s$critics_rating),
margin = 1)), 2)
addmargins(prop.table(table(dm_s$genre, # rows
dm_s$critics_rating), # columns
margin = 2)) # over columns
barplot(prop.table(table(dm_s$genre,
dm_s$critics_rating), margin=1),
xlab = "Ranking",
ylab = "Proportions",
main = "Critics Rating by Genre",
beside = TRUE,
legend.text = TRUE,
args.legend = list(x = 12,
y = 0.7,
cex = 0.8,
box.col = "white"))
png(filename = "barplot.png",
width = 600,
height = 350)
barplot(prop.table(table(dm_s$genre,
dm_s$critics_rating), margin=1),
xlab="Ranking",
ylab="Proportions",
main="Critics Rating by Genre",
beside=TRUE,
legend.text = TRUE,
args.legend = list(x=12,
y=0.7,
cex = 0.8,
box.col = "white"))
dev.off()
chisq.test(dm_s$genre,
dm_s$critics_rating)
sprintf("%.20f",1.097e-12)
chi <- chisq.test(dm_s$genre,
dm_s$critics_rating)
?chisq.test
str(chi)
# Returns the Pearson residuals, (observed - expected) / sqrt(expected)
chi$residuals
str(chi)
# Load data
df <- read.csv("fictional_data.csv")
plot(df$edu, df$income)
plot(df$edu, df$income,
col=df$cap+1) # Color over third variable (+1, because first color in R is white)
png(file="scatter_plot.png")
plot(df$edu,
df$income,
col = df$cap+1,
ylab = "Monthly net income (in Euro)",
xlab = "University level education (in years)",
main = "The Relationship between Education and Income")
cor(df$edu, df$income)
plot(df$edu, df$income)
text(6.5, 1000, sprintf("Correlation=%s", round(cor(df$income, df$edu), 4)))
png(file="scatter_plot.png")
plot(df$edu,
df$income,
col = df$cap+1,
ylab = "Monthly net income (in Euro)",
xlab = "University level education (in years)",
main = "The Relationship between Education and Income")
# Add legend
legend(0, 3000, # x and y position of legend
legend = c("Capital", "Non capital"),
col = c("red", "black"),
pch = 1,        # Marker type (1 is default)
cex = 0.5)
dev.off()
plot(df$edu, df$income)
text(6.5, 1000, sprintf("Correlation=%s", round(cor(df$income, df$edu), 4)))
regression1 <- lm(df$income ~ df$edu)
summary(regression1)
output_stargazer <- function(outputFile, ...) {
output <- capture.output(stargazer(...))
cat(paste(output, collapse = "\n"), "\n", file = outputFile, append = TRUE)
}
# execute function and check ls() to make sure it worked
output_stargazer("regression_output1.tex", regression1)
t.test(y, mu=100 )
sample_mean <- mean(y)
y <- c(105, 69, 86, 100, 82, 111, 104, 110, 87, 108, 87, 90, 94, 113, 112, 98, 80, 97, 95, 111, 114, 89, 95, 126, 98)
sample_mean <- mean(y)
t.test(y, mu=100 )
# scatter plot of X1,X2,X3,Y pairwise
pairs(expenditure[2:5])
expenditure <- read.table("https://raw.githubusercontent.com/ASDS-TCD/StatsI_Fall2024/main/datasets/expenditure.txt", header=T)
# scatter plot of X1,X2,X3,Y pairwise
pairs(expenditure[2:5])
plot(expenditure$Region,expenditure$Y)
aggregate(expenditure$ys, list(df$Region), FUN=mean)
aggregate(expenditure$Y, list(df$Region), FUN=mean)
aggregate(expenditure$Y, df$Region, FUN=mean)
aggregate(expenditure$Y, list(df$Region), FUN=mean)
aggregate(expenditure$Y, list(expenditure$Region), FUN=mean)
boxplot( expenditure$Y ~ expenditure$Region )
plot(expenditure$Y, expenditure$X1, col = expenditure$Region)
plot( expenditure$X1,expenditure$Y, col = expenditure$Region)
?plot
plot( expenditure$X1,expenditure$Y, col = expenditure$Region, pch = expenditure$Region)
CI
y <- c(105, 69, 86, 100, 82, 111, 104, 110, 87, 108, 87, 90, 94, 113, 112, 98, 80, 97, 95, 111, 114, 89, 95, 126, 98)
#Calculate lower and upper bound of confidence interval
CI <-c(
mean(y) - qt((1-0.9)/2 ,lower.tail = FALSE,df = 25 -1 )*sd(y)/sqrt(25)
, mean(y) + qt((1-0.9)/2 ,lower.tail = FALSE,df = 25 -1 )*sd(y)/sqrt(25)
)
CI
#calculate t-statistic
t = (sample_mean - 100)/(sd(y)/sqrt(25))
?pt
pt(t,df = 24,lower.tail = FALSE)
#calculae p-val
pt(t,df = 24,lower.tail = FALSE)
pdf("/Users/tpminh/Desktop/trinity asds/stat analysis 1/ps1/pairplot.pdf")
pairs(expenditure[2:5])
dev.off()
expenditure <- read.table("https://raw.githubusercontent.com/ASDS-TCD/StatsI_Fall2024/main/datasets/expenditure.txt", header=T)
# scatter plot of X1,X2,X3,Y pairwise
pdf("/Users/tpminh/Desktop/trinity asds/stat analysis 1/ps1/pairplot.pdf")
pairs(expenditure[2:5])
dev.off()
boxplot(expenditure$Y ~ expenditure$Region)
pdf("/Users/tpminh/Desktop/trinity asds/stat analysis 1/ps1/boxplot.pdf")
boxplot(expenditure$Y ~ expenditure$Region)
dev.off()
aggregate(expenditure$Y, list(expenditure$Region), FUN=mean)
?aggregate
aggregate(avg_exp = expenditure$Y, Region = list(expenditure$Region), FUN=mean)
aggregate(list(avg_exp = expenditure$Y), list(Region = expenditure$Region), FUN=mean)
list(avg_exp = expenditure$Y
list(avg_exp = expenditure$Y
list(avg_exp = expenditure$Y)
str(list(avg_exp = expenditure$Y))
aggregate(list(avg_exp = expenditure$Y), list(Region = expenditure$Region), FUN=mean)
##section 3
pdf("/Users/tpminh/Desktop/trinity asds/stat analysis 1/ps1/scatter1.pdf")
plot( expenditure$X1,expenditure$Y)
dev.off()
#change colour and symbol
pdf("/Users/tpminh/Desktop/trinity asds/stat analysis 1/ps1/scatter2.pdf")
plot( expenditure$X1,expenditure$Y, col = expenditure$Region, pch = expenditure$Region)
dev.off()
sampling_mean <- mean(y)
sampling_sd <- sd(y)/sqrt(25)
t_value <- qt((1-0.9)/2 ,lower.tail = FALSE,df = 25 -1 )
CI <- c(sampling_mean - t_value*sampling_sd,sampling_mean + t_value*sampling_sd )
CI
